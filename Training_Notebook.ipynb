{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ RoofVision AI - Training on Cloud GPU\n",
                "\n",
                "Use this notebook to train your model on **Google Colab** or **Kaggle** for free using a T4 GPU.\n",
                "\n",
                "### Steps:\n",
                "1.  **Run All Cells** from top to bottom.\n",
                "2.  Wait for training to finish (approx 10-15 mins for 10 epochs).\n",
                "3.  **Download** the `antigravity_model.pt` file at the end.\n",
                "4.  Upload it to your laptop's `solar 3/antigravity/backend/models/` folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install torch torchvision opencv-python-headless matplotlib pyyaml tqdm\n",
                "import torch\n",
                "print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Upload Your Dataset\n",
                "1. Click the **Files** icon on the left sidebar.\n",
                "2. Drag and drop your **`dataset_train`** and **`dataset_valid`** folders here.\n",
                "   * Tip: Zip them first (`dataset.zip`), upload, and run `!unzip dataset.zip` to be faster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (Optional) Unzip if you uploaded a zip file\n",
                "# !unzip dataset.zip"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Define the Model & Training Script\n",
                "\n",
                "import os\n",
                "import torch\n",
                "import torchvision\n",
                "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
                "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import cv2\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "\n",
                "def get_model_instance_segmentation(num_classes):\n",
                "    # Load pre-trained Mask R-CNN\n",
                "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
                "\n",
                "    # Replace box predictor\n",
                "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
                "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
                "\n",
                "    # Replace mask predictor\n",
                "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
                "    hidden_layer = 256\n",
                "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
                "\n",
                "    return model\n",
                "\n",
                "# --- IMPROVED DATASET CLASS (Supports Boxes & Polygons) ---\n",
                "class SolarDataset(Dataset):\n",
                "    def __init__(self, root, transforms=None):\n",
                "        self.root = root\n",
                "        self.transforms = transforms\n",
                "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
                "        self.labels = [f.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\") for f in self.imgs]\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
                "        label_path = os.path.join(self.root, \"labels\", self.labels[idx])\n",
                "\n",
                "        # 1. Load Image\n",
                "        img = cv2.imread(img_path)\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "        # 2. Normalize (0-1) - CRITICAL STEP\n",
                "        img = img.astype(np.float32) / 255.0\n",
                "\n",
                "        height, width, _ = img.shape\n",
                "\n",
                "        boxes, masks_list, labels = [], [], []\n",
                "\n",
                "        if os.path.exists(label_path):\n",
                "            with open(label_path) as f:\n",
                "                for line in f.readlines():\n",
                "                    parts = list(map(float, line.strip().split()))\n",
                "                    coords = parts[1:]\n",
                "\n",
                "                    poly_points = []\n",
                "\n",
                "                    # --- DETECTION LOGIC (Handling Box Format) ---\n",
                "                    if len(coords) == 4:\n",
                "                        # Format: cx, cy, w, h (Normalized)\n",
                "                        cx, cy, w_box, h_box = coords\n",
                "\n",
                "                        # Convert to corners\n",
                "                        x1 = int((cx - w_box/2) * width)\n",
                "                        y1 = int((cy - h_box/2) * height)\n",
                "                        x2 = int((cx + w_box/2) * width)\n",
                "                        y2 = int((cy + h_box/2) * height)\n",
                "\n",
                "                        # Create 4 points for the rectangle polygon\n",
                "                        poly_points = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]\n",
                "\n",
                "                    # --- SEGMENTATION LOGIC (Handling Polygon Format) ---\n",
                "                    else:\n",
                "                        for i in range(0, len(coords), 2):\n",
                "                            x = int(coords[i] * width)\n",
                "                            y = int(coords[i+1] * height)\n",
                "                            poly_points.append([x, y])\n",
                "\n",
                "                    if len(poly_points) < 3: continue\n",
                "\n",
                "                    # Create Mask\n",
                "                    mask = np.zeros((height, width), dtype=np.uint8)\n",
                "                    cv2.fillPoly(mask, [np.array(poly_points)], 1)\n",
                "                    masks_list.append(mask)\n",
                "\n",
                "                    # Create Box\n",
                "                    x_coords = [p[0] for p in poly_points]\n",
                "                    y_coords = [p[1] for p in poly_points]\n",
                "                    xmin, xmax = min(x_coords), max(x_coords)\n",
                "                    ymin, ymax = min(y_coords), max(y_coords)\n",
                "\n",
                "                    # Validate box area\n",
                "                    if xmax > xmin and ymax > ymin:\n",
                "                        boxes.append([xmin, ymin, xmax, ymax])\n",
                "                        labels.append(1) # Class 1 = Solar Panel\n",
                "\n",
                "        target = {}\n",
                "        if len(boxes) > 0:\n",
                "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.as_tensor(np.array(masks_list), dtype=torch.uint8)\n",
                "        else:\n",
                "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.zeros((0,), dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.zeros((0, height, width), dtype=torch.uint8)\n",
                "\n",
                "        target[\"image_id\"] = torch.tensor([idx])\n",
                "\n",
                "        # Convert Image to Tensor (CHW format)\n",
                "        img = torch.as_tensor(img.transpose((2, 0, 1)))\n",
                "\n",
                "        return img, target\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.imgs)\n",
                "\n",
                "def collate_fn(batch):\n",
                "    return tuple(zip(*batch))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Run Training (NUCLEAR OPTION - 100% STABLE)\n",
                "\n",
                "import os\n",
                "import torch\n",
                "import torchvision\n",
                "import cv2\n",
                "import numpy as np\n",
                "import gc\n",
                "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
                "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from tqdm import tqdm\n",
                "\n",
                "# ==========================================\n",
                "# 1. SETUP DATASET & MODEL\n",
                "# ==========================================\n",
                "\n",
                "def get_model_instance_segmentation(num_classes):\n",
                "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
                "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
                "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
                "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
                "    hidden_layer = 256\n",
                "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
                "    return model\n",
                "\n",
                "class SolarDataset(Dataset):\n",
                "    def __init__(self, root, transforms=None):\n",
                "        self.root = root\n",
                "        self.transforms = transforms\n",
                "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
                "        self.labels = [f.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\") for f in self.imgs]\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
                "        label_path = os.path.join(self.root, \"labels\", self.labels[idx])\n",
                "\n",
                "        # --- AGGRESSIVE RESIZE (Max 480px) ---\n",
                "        img = cv2.imread(img_path)\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "        # Calculate resize scale\n",
                "        h, w = img.shape[:2]\n",
                "        target_size = 480\n",
                "        scale = target_size / max(h, w)\n",
                "        if scale < 1.0:\n",
                "            img = cv2.resize(img, (0,0), fx=scale, fy=scale)\n",
                "\n",
                "        # Normalize\n",
                "        img = img.astype(np.float32) / 255.0\n",
                "        height, width, _ = img.shape # New dimensions\n",
                "\n",
                "        boxes, masks_list, labels = [], [], []\n",
                "\n",
                "        if os.path.exists(label_path):\n",
                "            with open(label_path) as f:\n",
                "                for line in f.readlines():\n",
                "                    try:\n",
                "                        parts = list(map(float, line.strip().split()))\n",
                "                        coords = parts[1:]\n",
                "                        poly_points = []\n",
                "\n",
                "                        if len(coords) == 4: # Box\n",
                "                            cx, cy, w_box, h_box = coords\n",
                "                            x1 = int((cx - w_box/2) * width)\n",
                "                            y1 = int((cy - h_box/2) * height)\n",
                "                            x2 = int((cx + w_box/2) * width)\n",
                "                            y2 = int((cy + h_box/2) * height)\n",
                "                            poly_points = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]\n",
                "                        else: # Polygon\n",
                "                            for i in range(0, len(coords), 2):\n",
                "                                poly_points.append([int(coords[i] * width), int(coords[i+1] * height)])\n",
                "\n",
                "                        if len(poly_points) < 3: continue\n",
                "\n",
                "                        mask = np.zeros((height, width), dtype=np.uint8)\n",
                "                        cv2.fillPoly(mask, [np.array(poly_points)], 1)\n",
                "                        masks_list.append(mask)\n",
                "\n",
                "                        x_coords = [p[0] for p in poly_points]\n",
                "                        y_coords = [p[1] for p in poly_points]\n",
                "                        boxes.append([min(x_coords), min(y_coords), max(x_coords), max(y_coords)])\n",
                "                        labels.append(1)\n",
                "                    except: continue\n",
                "\n",
                "        target = {}\n",
                "        if len(boxes) > 0:\n",
                "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.as_tensor(np.array(masks_list), dtype=torch.uint8)\n",
                "        else:\n",
                "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.zeros((0,), dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.zeros((0, height, width), dtype=torch.uint8)\n",
                "\n",
                "        target[\"image_id\"] = torch.tensor([idx])\n",
                "        img = torch.as_tensor(img.transpose((2, 0, 1)))\n",
                "        return img, target\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.imgs)\n",
                "\n",
                "def collate_fn(batch):\n",
                "    return tuple(zip(*batch))\n",
                "\n",
                "def get_batch_stats(predictions, targets, iou_threshold=0.5):\n",
                "    tp, fp, fn, matched_iou, matched_instances = 0, 0, 0, 0, 0\n",
                "    for img_preds, img_targets in zip(predictions, targets):\n",
                "        keep = img_preds['scores'] > 0.05\n",
                "        pred_scores = img_preds['scores'][keep]\n",
                "        pred_masks = img_preds['masks'][keep]\n",
                "        gt_masks = img_targets['masks']\n",
                "\n",
                "        if len(gt_masks) == 0 and len(pred_masks) == 0: continue\n",
                "        if len(gt_masks) == 0: fp += len(pred_masks); continue\n",
                "        if len(pred_masks) == 0: fn += len(gt_masks); continue\n",
                "\n",
                "        if pred_masks.dim() == 4: pred_masks = pred_masks.squeeze(1)\n",
                "        if gt_masks.dim() == 4: gt_masks = gt_masks.squeeze(1)\n",
                "\n",
                "        iou_matrix = ((pred_masks > 0.5)[:, None] & gt_masks.bool()[None, :]).sum((2,3)).float() / \\\n",
                "                     torch.clamp(((pred_masks > 0.5)[:, None] | gt_masks.bool()[None, :]).sum((2,3)).float(), min=1e-6)\n",
                "\n",
                "        pred_matched = torch.zeros(len(pred_masks), dtype=torch.bool)\n",
                "        gt_matched = torch.zeros(len(gt_masks), dtype=torch.bool)\n",
                "\n",
                "        for pred_idx in torch.argsort(pred_scores, descending=True):\n",
                "            if pred_matched[pred_idx]: continue\n",
                "            best_iou, best_gt = 0.0, -1\n",
                "            for gt_idx in range(len(gt_masks)):\n",
                "                if gt_matched[gt_idx]: continue\n",
                "                if iou_matrix[pred_idx, gt_idx] > best_iou: best_iou, best_gt = iou_matrix[pred_idx, gt_idx], gt_idx\n",
                "            if best_iou >= iou_threshold and best_gt != -1:\n",
                "                tp += 1; matched_iou += best_iou.item(); matched_instances += 1\n",
                "                pred_matched[pred_idx] = True; gt_matched[best_gt] = True\n",
                "            else: fp += 1\n",
                "        fn += (gt_matched == False).sum().item()\n",
                "    return tp, fp, fn, matched_iou, matched_instances\n",
                "\n",
                "# ==========================================\n",
                "# 2. RUN TRAINING\n",
                "# ==========================================\n",
                "\n",
                "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "gc.collect(); torch.cuda.empty_cache()\n",
                "\n",
                "train_dir, valid_dir = \"./dataset_train/\", \"./dataset_valid/\"\n",
                "\n",
                "if not os.path.exists(train_dir):\n",
                "    print(f\"‚ùå Error: {train_dir} not found! Did you unzip?\")\n",
                "else:\n",
                "    print(f\"‚úÖ Found Dataset at {train_dir}\")\n",
                "    print(\"‚ö° Training with BATCH_SIZE=1 and RESIZE=480px (Safe Mode)\")\n",
                "\n",
                "    dataset = SolarDataset(train_dir)\n",
                "    valid_dataset = SolarDataset(valid_dir)\n",
                "\n",
                "    # BATCH SIZE 1 (Very safe)\n",
                "    train_loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
                "    valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
                "\n",
                "    model = get_model_instance_segmentation(2).to(device)\n",
                "    optimizer = torch.optim.SGD([p for p in model.parameters() if p.requires_grad], lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
                "\n",
                "    num_epochs = 10\n",
                "    print(\"üöÄ Starting Training...\")\n",
                "\n",
                "    for epoch in range(num_epochs):\n",
                "        model.train()\n",
                "        total_loss = 0\n",
                "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Train\")\n",
                "\n",
                "        for images, targets in pbar:\n",
                "            images = list(img.to(device) for img in images)\n",
                "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
                "            loss_dict = model(images, targets)\n",
                "            losses = sum(loss for loss in loss_dict.values())\n",
                "            optimizer.zero_grad()\n",
                "            losses.backward()\n",
                "            optimizer.step()\n",
                "            total_loss += losses.item()\n",
                "            pbar.set_postfix({'loss': losses.item()})\n",
                "            del images, targets, loss_dict, losses # CLEAN\n",
                "\n",
                "        # VALIDATION (Only first 40 images to check health)\n",
                "        model.eval()\n",
                "        epoch_tp, epoch_fp, epoch_fn, epoch_iou_sum, epoch_iou_count = 0, 0, 0, 0, 0\n",
                "        val_count = 0\n",
                "\n",
                "        with torch.no_grad():\n",
                "            for images, targets in tqdm(valid_loader, desc=f\"Epoch {epoch+1} Valid\"):\n",
                "                if val_count > 40: break # STOP validation early to create checkpoints faster\n",
                "                val_count += 1\n",
                "\n",
                "                images = list(img.to(device) for img in images)\n",
                "                preds = model(images)\n",
                "\n",
                "                # Move to CPU immediately\n",
                "                preds_cpu = [{k: v.to('cpu') for k, v in p.items()} for p in preds]\n",
                "                targets_cpu = [{k: v.to('cpu') for k, v in t.items()} for t in targets]\n",
                "\n",
                "                tp, fp, fn, miou, minnst = get_batch_stats(preds_cpu, targets_cpu)\n",
                "                epoch_tp += tp; epoch_fp += fp; epoch_fn += fn\n",
                "                epoch_iou_sum += miou; epoch_iou_count += minnst\n",
                "                del images, targets, preds, preds_cpu, targets_cpu\n",
                "\n",
                "        precision = epoch_tp / (epoch_tp + epoch_fp) if (epoch_tp + epoch_fp) > 0 else 0.0\n",
                "        recall = epoch_tp / (epoch_tp + epoch_fn) if (epoch_tp + epoch_fn) > 0 else 0.0\n",
                "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
                "        final_iou = epoch_iou_sum / epoch_iou_count if epoch_iou_count > 0 else 0.0\n",
                "\n",
                "        print(f\"   Train Loss: {total_loss/len(train_loader):.4f}\")\n",
                "        print(f\"   Precision:  {precision:.4f} | Recall: {recall:.4f}\")\n",
                "        print(f\"   F1 Score:   {f1:.4f}      | IoU:    {final_iou:.4f}\")\n",
                "\n",
                "    torch.save(model.state_dict(), \"antigravity_model.pt\")\n",
                "    print(\"\\nüèÅ DONE! Run next cell to download.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Download the Brain\n",
                "from google.colab import files\n",
                "files.download('antigravity_model.pt')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DIAGNOSTIC SCRIPT\n",
                "dataset = SolarDataset(\"./dataset_train/\")\n",
                "print(f\"Total dataset size: {len(dataset)}\")\n",
                "\n",
                "# Check first 5 images\n",
                "for i in range(5):\n",
                "    img, target = dataset[i]\n",
                "    num_boxes = len(target[\"boxes\"])\n",
                "    print(f\"Image {i}: Found {num_boxes} solar panels\")\n",
                "\n",
                "    if num_boxes == 0:\n",
                "        # Check if label file actually exists\n",
                "        img_filename = dataset.imgs[i]\n",
                "        label_filename = dataset.labels[i]\n",
                "        expected_path = os.path.join(dataset.root, \"labels\", label_filename)\n",
                "        print(f\"   ‚ùå WARNING: No labels loaded! Checked path: {expected_path}\")\n",
                "        print(f\"      File exists? {os.path.exists(expected_path)}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
