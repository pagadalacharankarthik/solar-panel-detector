{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ RoofVision AI - Training on Cloud GPU\n",
                "\n",
                "Use this notebook to train your model on **Google Colab** or **Kaggle** for free using a T4 GPU.\n",
                "\n",
                "### Steps:\n",
                "1.  **Run All Cells** from top to bottom.\n",
                "2.  Wait for training to finish (approx 10-15 mins for 10 epochs).\n",
                "3.  **Download** the `antigravity_model.pt` file at the end.\n",
                "4.  Upload it to your laptop's `solar 3/antigravity/backend/models/` folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install torch torchvision opencv-python-headless matplotlib pyyaml tqdm\n",
                "import torch\n",
                "print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Upload Your Dataset\n",
                "1. Click the **Files** icon on the left sidebar.\n",
                "2. Drag and drop your **`dataset_train`** and **`dataset_valid`** folders here.\n",
                "   * Tip: Zip them first (`dataset.zip`), upload, and run `!unzip dataset.zip` to be faster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (Optional) Unzip if you uploaded a zip file\n",
                "# !unzip dataset.zip"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Define the Model & Training Script\n",
                "# (We paste the code directly here to avoid cloning complex repos)\n",
                "\n",
                "import os\n",
                "import torch\n",
                "import torchvision\n",
                "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
                "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import cv2\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "\n",
                "def get_model_instance_segmentation(num_classes):\n",
                "    # Load pre-trained Mask R-CNN\n",
                "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
                "    \n",
                "    # Replace box predictor\n",
                "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
                "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
                "    \n",
                "    # Replace mask predictor\n",
                "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
                "    hidden_layer = 256\n",
                "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
                "    \n",
                "    return model\n",
                "\n",
                "class SolarDataset(Dataset):\n",
                "    def __init__(self, root, transforms=None):\n",
                "        self.root = root\n",
                "        self.transforms = transforms\n",
                "        # Load all images\n",
                "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
                "        label_path = os.path.join(self.root, \"labels\", self.imgs[idx].replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
                "        \n",
                "        img = cv2.imread(img_path)\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "        height, width, _ = img.shape\n",
                "        \n",
                "        # Parse Labels (YOLO Format -> Mask)\n",
                "        boxes, masks_list, labels = [], [], []\n",
                "        \n",
                "        if os.path.exists(label_path):\n",
                "            with open(label_path) as f:\n",
                "                for line in f.readlines():\n",
                "                    parts = list(map(float, line.strip().split()))\n",
                "                    class_id = int(parts[0])\n",
                "                    poly_points = parts[1:]\n",
                "                    \n",
                "                    pts = []\n",
                "                    for i in range(0, len(poly_points), 2):\n",
                "                        x = int(poly_points[i] * width)\n",
                "                        y = int(poly_points[i+1] * height)\n",
                "                        pts.append([x, y])\n",
                "                    \n",
                "                    if len(pts) < 3: continue\n",
                "                    \n",
                "                    # Create Mask\n",
                "                    mask = np.zeros((height, width), dtype=np.uint8)\n",
                "                    cv2.fillPoly(mask, [np.array(pts)], 1)\n",
                "                    masks_list.append(mask)\n",
                "                    \n",
                "                    # Create Box\n",
                "                    x_coords = [p[0] for p in pts]\n",
                "                    y_coords = [p[1] for p in pts]\n",
                "                    boxes.append([min(x_coords), min(y_coords), max(x_coords), max(y_coords)])\n",
                "                    labels.append(1) # Class 1 = Solar Panel\n",
                "        \n",
                "        # Convert to Tensor\n",
                "        target = {}\n",
                "        if len(boxes) > 0:\n",
                "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.as_tensor(np.array(masks_list), dtype=torch.uint8)\n",
                "        else:\n",
                "             # Negative example (no solar)\n",
                "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
                "            target[\"labels\"] = torch.zeros((0,), dtype=torch.int64)\n",
                "            target[\"masks\"] = torch.zeros((0, height, width), dtype=torch.uint8)\n",
                "\n",
                "        img = torchvision.transforms.functional.to_tensor(img)\n",
                "        return img, target\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.imgs)\n",
                "\n",
                "def collate_fn(batch):\n",
                "    return tuple(zip(*batch))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Run Training\n",
                "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "\n",
                "# Paths (Make sure these match where you uploaded/unzipped)\n",
                "train_dir = \"./dataset_train/\" \n",
                "valid_dir = \"./dataset_valid/\"\n",
                "\n",
                "dataset = SolarDataset(train_dir)\n",
                "data_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
                "\n",
                "model = get_model_instance_segmentation(2)\n",
                "model.to(device)\n",
                "\n",
                "params = [p for p in model.parameters() if p.requires_grad]\n",
                "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
                "\n",
                "num_epochs = 10 # <-- CHANGE EPOCHS HERE\n",
                "\n",
                "print(\"Starting Training...\")\n",
                "for epoch in range(num_epochs):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    for images, targets in tqdm(data_loader):\n",
                "        images = list(image.to(device) for image in images)\n",
                "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
                "        \n",
                "        loss_dict = model(images, targets)\n",
                "        losses = sum(loss for loss in loss_dict.values())\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        losses.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += losses.item()\n",
                "        \n",
                "    print(f\"Epoch {epoch+1}/{num_epochs} finished. Avg Loss: {total_loss/len(data_loader)}\")\n",
                "\n",
                "# Save\n",
                "torch.save(model.state_dict(), \"antigravity_model.pt\")\n",
                "print(\"Model Saved! Run the next cell to download.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Download the Brain\n",
                "from google.colab import files\n",
                "files.download('antigravity_model.pt')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}