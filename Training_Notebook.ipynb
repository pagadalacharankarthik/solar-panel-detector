{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ RoofVision AI - Training on Cloud GPU\n",
                "\n",
                "Use this notebook to train your model on **Google Colab** or **Kaggle** for free using a T4 GPU.\n",
                "\n",
                "### Steps:\n",
                "1.  **Run All Cells** from top to bottom.\n",
                "2.  Wait for training to finish (approx 10-15 mins for 10 epochs).\n",
                "3.  **Download** the `antigravity_model.pt` file at the end.\n",
                "4.  Upload it to your laptop's `solar 3/antigravity/backend/models/` folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install torch torchvision opencv-python-headless matplotlib pyyaml tqdm\n",
                "import torch\n",
                "print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Upload Your Dataset\n",
                "1. Click the **Files** icon on the left sidebar.\n",
                "2. Drag and drop your **`dataset_train`** and **`dataset_valid`** folders here.\n",
                "   * Tip: Zip them first (`dataset.zip`), upload, and run `!unzip dataset.zip` to be faster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (Optional) Unzip if you uploaded a zip file\n",
                "# !unzip dataset.zip"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                # 3. Define the Model & Training Script

import os
import torch
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
from torch.utils.data import Dataset, DataLoader
import cv2
import numpy as np
from tqdm import tqdm

def get_model_instance_segmentation(num_classes):
    # Load pre-trained Mask R-CNN
    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)

    # Replace box predictor
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

    # Replace mask predictor
    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    hidden_layer = 256
    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)

    return model

# --- IMPROVED DATASET CLASS (Supports Boxes & Polygons) ---
class SolarDataset(Dataset):
    def __init__(self, root, transforms=None):
        self.root = root
        self.transforms = transforms
        self.imgs = list(sorted(os.listdir(os.path.join(root, "images"))))
        self.labels = [f.replace(".jpg", ".txt").replace(".png", ".txt") for f in self.imgs]

    def __getitem__(self, idx):
        img_path = os.path.join(self.root, "images", self.imgs[idx])
        label_path = os.path.join(self.root, "labels", self.labels[idx])

        # 1. Load Image
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # 2. Normalize (0-1) - CRITICAL STEP
        img = img.astype(np.float32) / 255.0

        height, width, _ = img.shape

        boxes, masks_list, labels = [], [], []

        if os.path.exists(label_path):
            with open(label_path) as f:
                for line in f.readlines():
                    parts = list(map(float, line.strip().split()))
                    coords = parts[1:]

                    poly_points = []

                    # --- DETECTION LOGIC (Handling Box Format) ---
                    if len(coords) == 4:
                        # Format: cx, cy, w, h (Normalized)
                        cx, cy, w_box, h_box = coords

                        # Convert to corners
                        x1 = int((cx - w_box/2) * width)
                        y1 = int((cy - h_box/2) * height)
                        x2 = int((cx + w_box/2) * width)
                        y2 = int((cy + h_box/2) * height)

                        # Create 4 points for the rectangle polygon
                        poly_points = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]

                    # --- SEGMENTATION LOGIC (Handling Polygon Format) ---
                    else:
                        for i in range(0, len(coords), 2):
                            x = int(coords[i] * width)
                            y = int(coords[i+1] * height)
                            poly_points.append([x, y])

                    if len(poly_points) < 3: continue

                    # Create Mask
                    mask = np.zeros((height, width), dtype=np.uint8)
                    cv2.fillPoly(mask, [np.array(poly_points)], 1)
                    masks_list.append(mask)

                    # Create Box
                    x_coords = [p[0] for p in poly_points]
                    y_coords = [p[1] for p in poly_points]
                    xmin, xmax = min(x_coords), max(x_coords)
                    ymin, ymax = min(y_coords), max(y_coords)

                    # Validate box area
                    if xmax > xmin and ymax > ymin:
                        boxes.append([xmin, ymin, xmax, ymax])
                        labels.append(1) # Class 1 = Solar Panel

        target = {}
        if len(boxes) > 0:
            target["boxes"] = torch.as_tensor(boxes, dtype=torch.float32)
            target["labels"] = torch.as_tensor(labels, dtype=torch.int64)
            target["masks"] = torch.as_tensor(np.array(masks_list), dtype=torch.uint8)
        else:
            target["boxes"] = torch.zeros((0, 4), dtype=torch.float32)
            target["labels"] = torch.zeros((0,), dtype=torch.int64)
            target["masks"] = torch.zeros((0, height, width), dtype=torch.uint8)

        target["image_id"] = torch.tensor([idx])

        # Convert Image to Tensor (CHW format)
        img = torch.as_tensor(img.transpose((2, 0, 1)))

        return img, target

    def __len__(self):
        return len(self.imgs)

def collate_fn(batch):
    return tuple(zip(*batch))
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Run Training\n",
                "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "\n",
                "# Paths (Make sure these match where you uploaded/unzipped)\n",
                "train_dir = \"./dataset_train/\" \n",
                "valid_dir = \"./dataset_valid/\"\n",
                "\n",
                "dataset = SolarDataset(train_dir)\n",
                "data_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
                "\n",
                "model = get_model_instance_segmentation(2)\n",
                "model.to(device)\n",
                "\n",
                "params = [p for p in model.parameters() if p.requires_grad]\n",
                "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
                "\n",
                "num_epochs = 10 # <-- CHANGE EPOCHS HERE\n",
                "\n",
                "print(\"Starting Training...\")\n",
                "for epoch in range(num_epochs):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    for images, targets in tqdm(data_loader):\n",
                "        images = list(image.to(device) for image in images)\n",
                "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
                "        \n",
                "        loss_dict = model(images, targets)\n",
                "        losses = sum(loss for loss in loss_dict.values())\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        losses.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += losses.item()\n",
                "        \n",
                "    print(f\"Epoch {epoch+1}/{num_epochs} finished. Avg Loss: {total_loss/len(data_loader)}\")\n",
                "\n",
                "# Save\n",
                "torch.save(model.state_dict(), \"antigravity_model.pt\")\n",
                "print(\"Model Saved! Run the next cell to download.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Download the Brain\n",
                "from google.colab import files\n",
                "files.download('antigravity_model.pt')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
